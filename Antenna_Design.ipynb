{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "project1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9697219-f170-4257-863d-b4235d3b283c"
      },
      "source": [
        "# Module 1 Project\n",
        "\n",
        "## Project overview\n",
        "\n",
        "In this project, you will choose a dataset and problem based on your specialization or interests in Electrical and Computer Engineering.  You will decide how you want to solve the problem using the given dataset, then create the code and writeup necessary for others to understand how you solved the problem.  You then have the option of using [Canvas Studio](https://community.canvaslms.com/t5/Studio/How-do-I-record-a-Canvas-Studio-screen-capture-video-in-a-course/ta-p/1713) to record a video presentation of the problem and your solution, walking through your thought process and code.  If you choose not to make a recording, then you must write your thought process and conclusions in detail within Markdown cells.\n",
        "\n",
        "## Project rubric\n",
        "\n",
        "The project is graded out of 10 points. Points are awarded as follows:\n",
        "\n",
        "- 2 points possible for a correct statistical interpretation of the problem\n",
        "    - In other words, make sure you state at the top the type of statistical analysis \n",
        "      you will use to solve the problem and why you chose to perform this type of analysis\n",
        "      given the dataset and the problem description.\n",
        "- 2 points possible for the correct statistical analysis flow implemented based on interpretation\n",
        "    - In other words, make sure that the analytical flow you implement throughout your notebook and \n",
        "      video is consistent with the type of statistical analysis you chose to solve the problem.\n",
        "- 2 points possible for clear Python code logic and intention\n",
        "    - In other words, make sure that you utilize Markdown and code cells to explain the steps you are\n",
        "      taking with code that is written.  For example, if you have a code cell that adds a new column\n",
        "      to a DataFrame (such as when using dummy variables), make sure you explain why you are adding\n",
        "      this new column.\n",
        "- 2 points possible for clear, readable Python code organization\n",
        "    - In other words, if you have any code that needs to be repeated, try to create functions rather\n",
        "      than copy/pasting the same code multiple times. Your code does not need to be perfect, but it \n",
        "      should be readable and easily followed. If you create a function, make sure to include the\n",
        "      function header so that others can understand the purpose and parameters/returns of your function.\n",
        "- 2 point possible for the audio-video presentation or detailed Markdown text explanations\n",
        "    - In other words, if you do not want to record a video explanation, then you must have your\n",
        "      statistical analysis and corresponding Python code well-explained on paper.\n",
        "      \n",
        "If any academic dishonesty is found (any similarities between submitted work or work posted on the Internet that are unexplained), you will receive zero points on this assignment, fail the course, and be referred to the academic dishonesty office, which may result in grounds for dismissal from the MSEE program at Cal State LA.  \n",
        "\n",
        "In other words, do your own work, make sure any analyses you run are justified in explanation either in writing or on the video, and do not work with others for this assignment."
      ],
      "id": "e9697219-f170-4257-863d-b4235d3b283c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d9a54ce-083d-4ae0-953d-3cde0e9fb72e"
      },
      "source": [
        "## Select a problem based on your specialization in ECE:\n",
        "\n",
        "Scroll down until you see one of your specializations (sorted alphabetically) and choose a problem.\n",
        "\n",
        "Then, delete the text of all of the other problems, leaving just the problem you are working to solve below.\n",
        "\n",
        "\n",
        "**Biomedical engineering**: Body fat measurement mechanism design\n",
        "\n",
        "_Dataset:_ `project_datasets/bme_bodyfat.csv`\n",
        "\n",
        "_Dataset description:_ This is a dataset of humans and different measurements on their body. Columns:\n",
        "1. Density (target, density of subject in grams per cubic centimeter)\n",
        "2. BodyFat (target, body fat percentage based on density)\n",
        "3. Age (in years)\n",
        "4. Weight (in pounds)\n",
        "5. Height (in inches)\n",
        "6. Neck (circumference in cm)\n",
        "7. Chest (circumference in cm)\n",
        "8. Abdomen (circumference in cm)\n",
        "9. Hip (circumference in cm)\n",
        "10. Thigh (circumference in cm)\n",
        "11. Knee (circumference in cm)\n",
        "12. Ankle (circumference in cm)\n",
        "13. Biceps (circumference in cm)\n",
        "14. Forearm (circumference in cm)\n",
        "15. Wrist (circumference in cm)\n",
        "\n",
        "_Problem:_ Is it possible to estimate body fat percentage using the given data without using density?  If so, which features matter?  Do the features that matter make sense? Why or why not?\n",
        "\n",
        "\n",
        "**Communications/electronics engineering**: Antenna design\n",
        "\n",
        "_Dataset:_ `project_datasets/comm_antenna.csv`\n",
        "\n",
        "_Dataset description:_ This is a dataset of different antenna designs. Columns:\n",
        "1. TestFreq (frequency used for testing the signal strength)\n",
        "2. PatchLength (length of patch antenna in mm)\n",
        "3. PatchWidth (width of patch antenna in mm)\n",
        "4. SlotLength (length of slot in antenna in mm)\n",
        "5. SlotWidth (width of slot in antenna in mm)\n",
        "6. Strength (signal strength in dB, higher is better)\n",
        "\n",
        "_Problem:_ Is it possible to create a statistical model that can estimate signal strength based on these parameters? Additionally, is it possible to create a model that only use the parameters that are not the test frequency?  What are the best accuracies of your statistical models?\n",
        "\n",
        "\n",
        "**Computer engineering**: GPU workload design\n",
        "\n",
        "_Dataset:_ `project_datasets/computer_gpu.csv`\n",
        "\n",
        "_Dataset description:_ This is a dataset from running an OpenCL benchmark on an AMD GPU. This benchmark breaks up matrix math by resizing a very large matrix (or large number of matrices) into matrices that can fit in hardware memory and cache by using a third dimension. Columns:\n",
        "1. Workgrp_m (Workgroup size (number of compute units) used for first dimension of matrices)\n",
        "2. Workgrp_n (Workgroup size (number of compute units) used for second dimension of matrices)\n",
        "3. Workgrp_k (Workgroup size (number of compute units) used for third dimension of matrices)\n",
        "4. Local_m (Local workgroup size (number of kernels running on one compute unit) used for first dimension of matrices)\n",
        "5. Local_n (Local workgroup size (number of kernels running on one compute unit) used for second dimension of matrices)\n",
        "6. Mem_m (Local memory length used for first dimension of matrices)\n",
        "7. Mem_n (Local memory length used for second dimension of matrices)\n",
        "8. Kernel_unroll (Number of times loops are unrolled)\n",
        "9. VectorWidth_m (Width of vector instruction used for first dimension of matrices)\n",
        "10. VectorWidth_n (Width of vector instruction used for second dimension of matrices)\n",
        "11. Stride_m (Use of off-chip memory for the first dimension of matrices)\n",
        "12. Stride_n (Use of off-chip memory for the second dimension of matrices)\n",
        "13. Cache_A (Use of caching scheme A)\n",
        "14. Cache_B (Use of caching scheme B)\n",
        "15. Runtime (target, runtime in ms)\n",
        "\n",
        "\n",
        "_Problem:_ For this GPU, which features of the OpenCL benchmark seem to affect runtime the largest? Which statistical modeling technique works best to predict the runtime based on this data? If so, which features are the most important for your model?\n",
        "\n",
        "\n",
        "**Power Engineering**: Solar power generator\n",
        "\n",
        "_Dataset:_ `project_datasets/power_solarplant.csv`\n",
        "\n",
        "_Dataset description:_ This is a dataset from a solar power plant. Columns:\n",
        "1. DateTime (Date and time in MM/DD/YYYY HH:MM format)\n",
        "2. AmbientTemp (Plant-wide ambient temperature in degC)\n",
        "3. ModuleTemp (Mean panel temperature in degC)\n",
        "4. Irradiation (irradiance at measurement time in W/m^2)\n",
        "5. PowerDC (DC power generated by this plant in kW)\n",
        "6. PowerAC (AC power generated by this plant in kW)\n",
        "\n",
        "_Problem:_ Can ambient temperature, module temperature, and irradiation provide a reasonable estimate for the DC power generated by this solar power plant?  Does your answer to the former question make sense?  Why or why not?  What is the maximum accuracy of your statistical model?"
      ],
      "id": "0d9a54ce-083d-4ae0-953d-3cde0e9fb72e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TTQ5a9JU8fS"
      },
      "source": [
        "Part a: Is it possible to create a statistical model that can estimate signal strength based on these parameters?\n",
        "\n",
        "Answer: Yes, Is it possible to create a statistical model that can estimate signal strength based on these parameters.\n"
      ],
      "id": "2TTQ5a9JU8fS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovM706sYLaN8",
        "outputId": "3e07c747-2fe0-4ea7-e3ba-2d787f071fba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "ovM706sYLaN8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd4c7b2b-a841-4f8c-b316-362598e76e97"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "id": "fd4c7b2b-a841-4f8c-b316-362598e76e97",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTmTOHXgLaxe"
      },
      "source": [
        "#reading dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Dataset/comm_antenna.csv')"
      ],
      "id": "xTmTOHXgLaxe",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "y0mZ3SfBL3gO",
        "outputId": "c1754163-3cd7-4225-892c-f0d658148601"
      },
      "source": [
        "data.head()"
      ],
      "id": "y0mZ3SfBL3gO",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TestFreq</th>\n",
              "      <th>PatchLength</th>\n",
              "      <th>PatchWidth</th>\n",
              "      <th>SlotLength</th>\n",
              "      <th>SlotWidth</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.500000</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-4.927274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.551724</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5.077877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.603448</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5.183708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.655172</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5.215997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.706897</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5.120009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TestFreq  PatchLength  PatchWidth  SlotLength  SlotWidth  Strength\n",
              "0  1.500000         33.0          33         0.0          0 -4.927274\n",
              "1  1.551724         33.0          33         0.0          0 -5.077877\n",
              "2  1.603448         33.0          33         0.0          0 -5.183708\n",
              "3  1.655172         33.0          33         0.0          0 -5.215997\n",
              "4  1.706897         33.0          33         0.0          0 -5.120009"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZSrLryVTvog",
        "outputId": "1b65fc11-3d7c-4d31-df03-a30dee36dd3c"
      },
      "source": [
        "#Checking Number of unique values does our columns have \n",
        "data.nunique()"
      ],
      "id": "4ZSrLryVTvog",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestFreq        279\n",
              "PatchLength       5\n",
              "PatchWidth        5\n",
              "SlotLength        6\n",
              "SlotWidth         6\n",
              "Strength       1266\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2yP1XxmVdXV"
      },
      "source": [
        "Part b: Additionally, is it possible to create a model that only use the parameters that are not the test frequency?"
      ],
      "id": "e2yP1XxmVdXV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgxRhbIzMDEH"
      },
      "source": [
        "X1 = data.drop(['TestFreq','Strength'], axis=1)\n",
        "y1 = data['Strength']\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3)"
      ],
      "id": "tgxRhbIzMDEH",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5BfkihYM-v9",
        "outputId": "29e7d42d-51dc-425d-b4db-12b5c0398831"
      },
      "source": [
        "models = [LinearRegression, ElasticNet, Lasso, DecisionTreeRegressor, RandomForestRegressor]\n",
        "for model in models:\n",
        " reg = model()\n",
        " reg.fit(X_train1,y_train1)\n",
        " pred1 = reg.predict(X_test1)\n",
        " err1 = mean_squared_error(y_test1, pred1) ** .5\n",
        " print(f'RMSE of {model.__name__} model is: {err1}')\n",
        " print(f'R2 value of {model.__name__} is: {np.mean(r2_score(y_test1, pred1))}')\n",
        " print('*'*50)"
      ],
      "id": "c5BfkihYM-v9",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of LinearRegression model is: 2.676241886875816\n",
            "R2 value of LinearRegression is: 0.28721183022604246\n",
            "**************************************************\n",
            "RMSE of ElasticNet model is: 2.7188484952980243\n",
            "R2 value of ElasticNet is: 0.26433554803939263\n",
            "**************************************************\n",
            "RMSE of Lasso model is: 2.762681278365111\n",
            "R2 value of Lasso is: 0.24042384111534953\n",
            "**************************************************\n",
            "RMSE of DecisionTreeRegressor model is: 2.6278146757974685\n",
            "R2 value of DecisionTreeRegressor is: 0.31277456777177237\n",
            "**************************************************\n",
            "RMSE of RandomForestRegressor model is: 2.624496871014825\n",
            "R2 value of RandomForestRegressor is: 0.314508815216624\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9unnmoyWKf0"
      },
      "source": [
        "Answer: Yes it's possible to create that kind of model but we will get too much bad results because the variable test frequency plays a vital role to estimate signal strength. For better understanding you can see bellow 2 cells for five regression model results and their R^2 values which give us a very clear picture how much important this attribute is for statical models."
      ],
      "id": "_9unnmoyWKf0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH09ahOAXaa-"
      },
      "source": [
        "What is the maximum accuracy of your statistical model?"
      ],
      "id": "SH09ahOAXaa-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zJVVuiTMTvr6",
        "outputId": "9df16b7d-53bb-412c-c530-a2e08006cc6b"
      },
      "source": [
        "'''Answer: Without considering the maximum accuracy is around 23% but when we consider TestFreq for essitmation of \n",
        "signal strength the accuracy reaches to 98% as shown in bellow cells'''"
      ],
      "id": "zJVVuiTMTvr6",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Answer: Without considering the maximum accuracy is around 23% but when we consider TestFreq for essitmation of \\nsignal strength the accuracy reaches to 98% as shown in bellow cells'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgCc8hFSTv7t"
      },
      "source": [
        "new_data = pd.read_csv('/content/drive/MyDrive/Dataset/comm_antenna.csv')"
      ],
      "id": "RgCc8hFSTv7t",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUjfHPi6aufX"
      },
      "source": [
        "X = new_data.drop(['Strength'], axis=1)\n",
        "y = new_data['Strength']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "id": "gUjfHPi6aufX",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQwIr1nxaui1",
        "outputId": "db3ff775-52e0-41b6-b157-882f61a838b8"
      },
      "source": [
        "models = [LinearRegression, ElasticNet, Lasso, DecisionTreeRegressor, RandomForestRegressor]\n",
        "for model in models:\n",
        " reg = model()\n",
        " reg.fit(X_train,y_train)\n",
        " pred = reg.predict(X_test)\n",
        " err = mean_squared_error(y_test, pred) ** .5\n",
        " print(f'RMSE of {model.__name__} model is: {err}')\n",
        " print(f'R2 value of {model.__name__} is: {np.mean(r2_score(y_test, pred))}')\n",
        " print('*'*50)"
      ],
      "id": "aQwIr1nxaui1",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of LinearRegression model is: 2.7611782684314625\n",
            "R2 value of LinearRegression is: 0.25005662488174607\n",
            "**************************************************\n",
            "RMSE of ElasticNet model is: 2.7941026554043513\n",
            "R2 value of ElasticNet is: 0.2320652935067815\n",
            "**************************************************\n",
            "RMSE of Lasso model is: 2.811382906304811\n",
            "R2 value of Lasso is: 0.2225372690799633\n",
            "**************************************************\n",
            "RMSE of DecisionTreeRegressor model is: 0.9954226952977892\n",
            "R2 value of DecisionTreeRegressor is: 0.9025336603929535\n",
            "**************************************************\n",
            "RMSE of RandomForestRegressor model is: 0.9306109888387203\n",
            "R2 value of RandomForestRegressor is: 0.9148124883454711\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "UXb2fJ5hNgYc",
        "outputId": "fe444f5a-d335-417c-ab12-feb59b862481"
      },
      "source": [
        "''' DecisionTreeRegressor and RandomForestRegressor are the best models among the these five models. However RandomForestRegressor model resulted much better their error is pretty low. Moreover 90%+ R^2 is also a good value. '''"
      ],
      "id": "UXb2fJ5hNgYc",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' DecisionTreeRegressor and RandomForestRegressor are the best models among the these five models. However RandomForestRegressor model resulted much better their error is pretty low. Moreover 90%+ R^2 is also a good value. '"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}